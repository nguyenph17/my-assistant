{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")\n",
    "import asyncio\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.utils.workflow import draw_all_possible_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstEvent(Event):\n",
    "    first_output: str\n",
    "\n",
    "\n",
    "class SecondEvent(Event):\n",
    "    second_output: str\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyWorkflow(Workflow):\n",
    "    @step\n",
    "    async def step_one(self, ctx: Context, ev: StartEvent) -> FirstEvent:\n",
    "        ctx.write_event_to_stream(Event(msg=\"Step one is happening\", length=0))\n",
    "        return FirstEvent(first_output=\"First step complete.\")\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ctx: Context, ev: FirstEvent) -> SecondEvent:\n",
    "        llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "        generator = await llm.astream_complete(\n",
    "            \"Write 3 sentences about Vietnam\"\n",
    "        )\n",
    "        async for response in generator:\n",
    "            # Allow the workflow to stream this piece of response\n",
    "            ctx.write_event_to_stream(Event(msg=response.delta))\n",
    "        return SecondEvent(\n",
    "            second_output=\"Second step complete, full response attached\",\n",
    "            response=str(response),\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ctx: Context, ev: SecondEvent) -> StopEvent:\n",
    "        ctx.write_event_to_stream(Event(msg=\"Step three is happening\", length=0))\n",
    "        return StopEvent(result=\"Workflow complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step one is happening ----\n",
      " ----\n",
      "Vietnam ----\n",
      " is ----\n",
      " a ----\n",
      " Southeast ----\n",
      " Asian ----\n",
      " country ----\n",
      " known ----\n",
      " for ----\n",
      " its ----\n",
      " rich ----\n",
      " history ----\n",
      ", ----\n",
      " vibrant ----\n",
      " culture ----\n",
      ", ----\n",
      " and ----\n",
      " stunning ----\n",
      " landscapes ----\n",
      ", ----\n",
      " ranging ----\n",
      " from ----\n",
      " lush ----\n",
      " rice ----\n",
      " terraces ----\n",
      " to ----\n",
      " bustling ----\n",
      " cities ----\n",
      ". ----\n",
      " The ----\n",
      " capital ----\n",
      ", ----\n",
      " Hanoi ----\n",
      ", ----\n",
      " is ----\n",
      " famous ----\n",
      " for ----\n",
      " its ----\n",
      " centuries ----\n",
      "-old ----\n",
      " architecture ----\n",
      " and ----\n",
      " a ----\n",
      " rich ----\n",
      " culinary ----\n",
      " scene ----\n",
      ", ----\n",
      " while ----\n",
      " Ho ----\n",
      " Chi ----\n",
      " Minh ----\n",
      " City ----\n",
      ", ----\n",
      " formerly ----\n",
      " Sa ----\n",
      "igon ----\n",
      ", ----\n",
      " is ----\n",
      " a ----\n",
      " bustling ----\n",
      " metropolis ----\n",
      " that ----\n",
      " showcases ----\n",
      " the ----\n",
      " country's ----\n",
      " rapid ----\n",
      " modernization ----\n",
      ". ----\n",
      " Vietnam ----\n",
      "'s ----\n",
      " diverse ----\n",
      " ethnic ----\n",
      " groups ----\n",
      " and ----\n",
      " traditions ----\n",
      " contribute ----\n",
      " to ----\n",
      " its ----\n",
      " unique ----\n",
      " cultural ----\n",
      " tapestry ----\n",
      ", ----\n",
      " making ----\n",
      " it ----\n",
      " a ----\n",
      " fascinating ----\n",
      " destination ----\n",
      " for ----\n",
      " travelers ----\n",
      ". ----\n",
      " ----\n",
      "Step three is happening ----\n",
      "Final result Workflow complete.\n",
      "Time taken 1.972930669784546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "async def main():\n",
    "    w = MyWorkflow(timeout=30, verbose=False)\n",
    "    task = asyncio.create_task(w.run(first_input=\"Start the workflow.\"))\n",
    "\n",
    "    async for ev in w.stream_events():\n",
    "        print(ev.msg, '----')\n",
    "\n",
    "    final_result = await task\n",
    "    print(\"Final result\", final_result)\n",
    "\n",
    "    # draw_all_possible_flows(MyWorkflow, filename=\"streaming_workflow.html\")\n",
    "\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "await main()\n",
    "print(\"Time taken\", time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    w = MyWorkflow(timeout=30, verbose=False)\n",
    "    task = asyncio.create_task(w.run(first_input=\"Start the workflow.\"))\n",
    "\n",
    "    final_result = await task\n",
    "    print(\"Final result\", final_result)\n",
    "\n",
    "    # draw_all_possible_flows(MyWorkflow, filename=\"streaming_workflow.html\")\n",
    "\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
